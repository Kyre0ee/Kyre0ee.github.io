---
layout: post
title: 第四章 
date: 2019-05-04 15:57 +0800
tags: 计组-MIPS汇编
toc: true
---
# 第四章 存储器
***
## 1.存储器概述
+ 信息的存储、传送、处理单位的含义
  - 记忆单元/编址单位/存储单位/传输单位/机器字长
  - 基本术语
    * 记忆单元（存储单元/存储元/位元）（cell）--具有两种稳态的能够表示二进制码0和1的物理器件。
    * 存储单元/编址单位（Addressing Unit）--主从中具有相同地址的位构成一个存储单元，也称为一个编址单位
    * 存储体/存储矩阵/存储阵列（Bank）--所有存储单元构成一个存储阵列
    * 编址方式（Addressing Mode）--字节编址、按字编址
    * 存储器地址寄存器（MAR）--用于存放主存单元地址的寄存器
    * 存储器数据寄存器（MDR）--用于存放主从单元中的数据的寄存器
+ 存储器分类
  - 可按存取方式/易失性/可更改性/元器件/功能来分
  - 1.按工作性质/存取方式分类
    * 随机存取存储器（RAM）:每个单元读写时间一样，且与各单元所在位置无关（如内存）。
    * 顺序存取存储器（SAM）:数据按顺序从存储载体的始端读出或写入，因而存取时间的长短与信息所在位置有关（如磁带）。
    * 直接存取存储器（DAM）:直接定位到要读写的数据块，在读写某个数据块时按顺序进行（如磁盘）。
    * 相联存储器（CAM）:按内容检索到存储位置进行读写（如：快表）。
  - 2.按存储介质分类
    * 半导体存储器：双极型，静态MOS型，动态MOS型
    * 磁表面存储器：磁盘、磁带
    * 光存储器：CD、CD-ROM、DVD
  - 3.按信息的可更改性分类
    * 读写存储器：可读可写
    * 只读存储器：只能读不能写
  - 4.按断电后的信息的可保存性分类
    * 非易失性存储器--信息可一直保留，不需要电源维持（如：ROM、磁表面存储器、光存储器等）。
    * 易失性存储器：电源关闭时信息自动丢失。（如RAM、Cache等）
  - 5.按功能/容量/速度/所在位置分类
    * 寄存器（Register）:分装在CPU内，用于存放当前正在执行的指令和使用的数据。用触发器实现，速度快，容量小（几十个）
    * 高速缓存（Cache）:位于CPU内部或附近，用来存放当前要执行的局部程序段和数据。用SRAM实现，速度可与CPU匹配，容量小（几MB）
    * 内存储器MM（主存储器Main(Primary)Memory）:位于CPU外，用来存放已被启动的程序及所用的数据。用DRAM实现，速度较快，容量较大（几GB）
    * 外存储器AM（辅助存储器Auxiliary/Secondary Storage）:位于主机之外，用来存放暂不运行的程序、数据或存档文件。用磁表面或光存储器实现，容量大而速度慢。
      ![image](https://github.com/Kyre0ee/Kyre0ee.github.io/assets/169347540/328052ba-5ea8-4524-ab57-2bec5f46dd21)
    * 外存与内存的关系及比较
      - 外存储器：存取速度慢，成本低，容量很大，不与CPU直接连接，先传送到内存，然后才能被CPU使用。属于非易失性存储器，用于长久存放系统中几乎所有信息。
      - 内存储器：存取速度快，成本高，容量较小，直接与CPU连接，CPU对内存中的指令及数据进行读、写操作。属于易失性存储器，用于临时存放正在运行的程序和数据。
+ 主存储器
  - 主存的结构
        问1：主存中存放的是什么信息？CPU何时会访问主存？
        答1：指令及其数据。CPU执行指令时需要取指令、取数据、存数据。
        问2：地址译码器的输入是什么？输出是什么？可寻址范围是多少？
        答2：输入是地址，输出是地址驱动信号（只有一根地址驱动线被选中）。可寻址范围0~2^36-1即主存地址空间为64GB按字节编址时。
        ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/a1dfb30e-3dcf-4ba8-b6fe-d311fe14a065)
        主存地址空间大小不等于主存容量（实际安装的主存大小）！若是字节编址，则每次最多可读/写8个单元，给出的是首（最小）地址。
  - 主存的主要性能指标
    - 按字节连续编址，每个存储单元为1个字节（8位）
    - 存储容量：所包含的存储单元的总数（单位：MB或GB）
    - 存取时间TA：从CPU送出内存单元的地址码开始，到主存读出数据并送到CPU（或者是把CPU数据写入主存）所需要的时间
    - 存取周期TMC:连续两次访问存储器所需的最小时间间隔，它应等于存取时间加上下一存取开始前所要求的附加时间，因此，Tmc比Ta大（因为存储器由于读出放大器、驱动电路等都有一段稳定恢复时间，所以读出后不能立即进行下一次访问）。
## 2.半导体存储器
+ 半导体存储器随机访问存储器
  - 内存由半导体存储芯片组成，芯片由多种类型：
      ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/7ab389ab-2cc7-4fc7-aea8-49a879eb3536)

  - SRAM的原理和特点
    6管静态NMOS记忆单元
    ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/1cbc423d-b10a-4ee1-bfa4-167d4c4acb3b)

    SRAM中数据保存在一对正负反馈门电路中，只要供电，数据就一直保持，不是破坏性读出，也无需重写，即无需刷新。
    信息存储原理：看作带时钟的RS触发器
    
  - DRAM的原理和特点
    动态单管记忆单元电路
    读写原理：字线上加高电平，使T管导通。写0时，数据线加低电平，使Cs上电荷对数据线放电。写1时，数据线加高电平，使数据线对Cs充电。读出时，数据线上有一读出电压。它与Cs上电荷量成正比。
    优点：电路元件少，功耗小，集成度高，用于构建主存存储
    缺点：速度慢、是破坏性读出（需读后再生）、需定时刷新
    刷新：DRAM的一个重要特点是，数据以电荷的形式保存在电容中，电容的放电使得电荷通常只能维持几十个毫秒左右，相当于1M个时钟周期左右，因此要定期进行刷新（读出后重写写回），按行进行（所有芯片中的同一行一起进行），刷新操作所需时间通常只占1%~2%左右。
+ RAM芯片组织
  - 如何由记忆单元构成存储阵列
    存储芯片：存储体+外围电路（地址译码和读写控制）
  - 如何读写存储阵列中的信息
  - 如何由芯片构成存储器
    为什么每出现新一代DRAM芯片，容量至少提高到4倍？
    行地址和列地址分时复用，每出现新一代DRAM芯片，至少要增加一根地址线。每加一根地址线，则行地址和列地址各增加1位，所以行数和列数各增加1倍。因而容量至少提高4倍。
    刷新周期：从上次对整个存储器刷新结束到下次对整个全部刷新一遍为止的时间间隔，也就是相邻两次对某个特定行进行刷新的时间间隔。为电容数据有效保存期的上限10ms~100ms，目前公认是64ms。
    多采用异步刷新方式：将一个刷新周期分配给所有行，使得在一个刷新周期内每行至少刷新一次，且仅刷新一次。
+ 提高存储器速度的措施
  - 芯片内采用行缓存，同行内数据直接从缓存中取
  - 采用多模块存储器，多个存储器交叉存取
  - 引入Cache
## 3.只读存储器ROM
随机存取方式，非易失性
* 只读存储器
  - 特点
    + 信息只能读不能在线写
    + 非破坏性读出，无需再生
    + 也以随机存取方式工作
    + 信息用特殊方式写入，一经写入，就可长久保留，不受断电影响。故是非易失性存储器
  - 用途
    + 用来存放一些固定程序。如监控程序、启动程序等。只要一接通电源，这些程序就能自动地运行；
    + 可作为控制存储器，存放微程序
    + 还可作为函数发生器和代码转换器
    + 在输入/出设备中，倍用作字符发生器，汉字库等。
    + 在嵌入式设备中用来存放固化的程序。
  - 分类
    + MROM:掩膜只读存储器
    + PROM:可编程只读存储器
    + EPROM:可擦除可编程只读存储器
    + EEPROM:电可擦除可编程只读存储器
    + flash memory:闪存（快擦存储器）快擦型电可擦除重编程ROM
      * 闪存靠在浮空栅上的存储信息，加足够电压浮空栅存1
      * 有三种操作：擦除、编程、读取 读快，写慢
## 4.主存与CPU的连接
* CPU和主存之间有同步和异步两种通信方式
  - 异步方式（读/写操作）过程（需要握手信号）
    + CPU送地址到地址线，主存进行地址译码
    + CPU发读命令，然后等待存储器发回完成信号
    + 主存收到读命令后开始读数，完成后发完成信号给CPU
    + CPU接收到完成信号，从数据线取数
  - 同步方式的特定
    + CPU和主存由统一时钟信号控制，无需应答信号
    + 主存总是在确定的时间内准备好数据
    + CPU送出地址和读命令后，总是在确定的时间取数据
    + 存储芯片必须支持同步方式
* SDRAM是同步存储芯片
  - 每步操作都在系统时钟控制下进行
  - 有确定的等待时间（读命令开始到数据线有效的时间，称为CAS潜伏期）CL,例如CL = 2clks
  - 连续传送数据个数BL= 1/2/4/8
  - 多体（缓冲器）交叉存取
  - 利用总线时钟上升沿与下降沿同步传送
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/8b57c12b-c01c-4697-9e50-d963d942ed0e)

## 存储器芯片的扩展
* 字扩展（位数不变、扩充容量）
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/7b36a40c-9fd7-4201-a8fb-fbf60a8d1467)

* 位扩展（字数不变，位数扩展）
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/4620b4cc-2f05-450d-b994-c3627869b265)

* 字位同时扩展（字和位同时扩展）
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/43a0ed35-c803-4169-aeea-c4b1de4ffbe4)
* 有两种容量扩展方式
  - 交叉编址
  - 连续编址
当CPU访问一块连续区域（即行地址相同）时，可直接从行缓冲读取，它用SRAM实现，速度极快。
解决内存访问速度慢的措施有三个
1. 提高主存芯片本身的速度
2. 采用多模块存储器技术
3. 在主存和CPU之间加入Cache
提高DRAM存储器速度的措施
1. 采用芯片内部行缓冲，以提高芯片本身的速度，反复多次使用芯片内部缓存中的内容，不需每次进行行访问。
2. 多模块存储器（能提高数据访问速度），包含多个小体，每个体有其自己的MAR\MDR和读写电路，可独立组成一个存储模块，可同时对多个模块进行访问。
3. 连续编址多模块存储器：按高位地址划分模块
4. 交叉编址多模块存储器：按低位地址划分模块 
## 5.Cache与程序访问的局部性
采用分层存储结构来构建计算机的存储体系。
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/214b20dd-bde9-41bb-837e-83b7413e10db)
分析：速度越快，成本越高
为提高性能/价格，组成一个层状塔式结构，取长补短，协调工作
工作过程：1）CPU运行时，需要的操作数大部分来自寄存器 2）如需要从（向）存储器中取（存）数据时，先访问cache,如在，取自cache 3) 如操作数不在cache，则访问DRAM，如在，则取自DRAM 4）如操作数不在DRAM，则访问硬盘，操作数从硬盘中读出->DRAM->cache.磁盘访问采用成批方式，主存访问则可能是单个数据或多个数据或一个主存块。
为什么这种层次化结构是有效的？因为程序访问局部化特点
* 时间局部性：含义：刚被访问过的单元很可能不久又被访问。做法：让最近被访问过的信息保留在靠近CPU的存储器中。
* 空间局部性：含义：刚被访问过的单元的临近单元很可能不久被访问。做法：将刚被访问过的单元的临近单元调到靠近CPU的存储器中。
* 什么是程序访问的局部化特性
  大量典型程序的运行情况分析结果表明：在较短时间间隔内，程序产生的地址往往集中在一个很小范围内，这种现象称为程序访问的局部性：空间局部性、时间局部性
  程序具有访问局部性特性的原因：指令按序存放，地址连续，循环程序段或子程序段重复执行。数据连续存放，数组元素重复，按序访问。
  为什么引入Cache会加速访存速度？在CPU和主存之间设置一个快速小容量的存储器，其中总是存放最活跃（被频繁访问）的程序块和数据，由于程序访问的局部性特征，大多数情况下，CPU能直接从这个高速缓存中取得指令和数据，而不必访问主存。
* 具有Cache机制的CPU的基本访存过程
  Cache是一种小容量的高速缓冲存储器，它由SRAM组成。
  Cache直接制作在CPU芯片内，速度几乎与CPU一样快
  程序运行时，CPU使用的一部分数据指令会预先成批拷贝在Cache中，Cache的内容是主存储器中部分内容的映像。
  当CPU需要从内存读写数据或指令时，先检查Cache，若有，就直接从Cache中读取，而不用访问主存储器。
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/880c1c7a-e9e7-4b67-842d-1f25003f549c)
* Cache容量和块大小的选择
问题：要实现Cache机制需要解决哪些问题？
如何分块？主存被分成若干大小相同的块，称为主存块。cache也被分成相同大小的块，称为Cache行(line)或槽（slot）
主存块和Cache之间如何映射？
Cache已满时，怎么办？
写数据时怎样保证Cache和MM的一致性？
如何根据主存地址访问到Cache中的数据？
问题： Cache对程序员（编译器）是否透明？为什么
是透明的，程序员（编译器）在编写/生成高级或低级语言程序时无需了解Cache是否存在或如何设置，感觉不到Cache的存在。但是对Cache深入了解有助于编写出高效的程序。
## 6.Cache与主存之间的映射方式
什么是Cache的映射功能？
把访问的局部主存区域取到Cache中时，该放到Cache的何处？
Cache槽比主存块少，多个主存块映射到一个cache槽中
* Cache和主存之间的映射方式
  - 直接映射：每个主存块映射到Cache的固定行中。也称模映射，映射关系为Cache行号=主存块号mod cache行数
    Cache标记（tag）指出对应行取自哪个主存块群。
    ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/85e2feda-cf10-42f0-8451-c3c5aae58a36)
   Cache有效位，通常为操作系统设置Cache冲刷指令，因此，cache对操作系统程序员不是透明的。
    特点：容易实现，命中时间短。无需考虑淘汰替换问题。但不够灵活，Cache存储空间得不到充分利用，命中率低。
    假如，需将主存第0块与第16块同时复制到Cache中时，由于它们都只能复制到Cache第0行，即使Cache其他行空闲，也有一个主存块不能写入Cache。这样就会产生频繁cache装入。
  - 全相联映射：每个主存块映射到Cache的任意行中
    特点：无需Cache索引，为什么？因为同时比较所有Cache项的标志。没有冲突缺失，因为只要有空闲Cache块，都不会发生冲突。
  - 组相联映射：每个主存块映射到Cache的固定组中的任意一行中
    组相联映射结合直接映射和全相联映射的特点。将Cache所有行分组，把主存块映射到Cache固定组的任一行中。也即：组间模映射、组内全映射。映射关系为：Cache组号=主存块号 mod Cache组数
    特点：结合直接映射和全相联映射的优点。当Cache组数为1时，变为相联映射；当每组只有一个槽时，变为直接映射。每组2或4行（称为2-路或4-路组相联）较常用。通常每组4行以上很少用。在较大容量的L2Cache 和L3 Cache中使用4路以上。
    N路组相联：N个直接映射的行并行操作
## 7.Cache替换算法
* 命中率、缺失率、缺失损失
  命中率：在Cache中的概率
  命中时间：在Cache中的访问时间，包括（判断时间+Cache访问）
  缺失率：1-命中率
  缺失损失：访问一个主存块所花时间
  平均访问时间T=HTc+(1-H)(Tc+Tm)=Tc+(1-H)Tm
* 高速缓存的缺失率和关联度
  什么叫关联度？一个主存块映射到Cache中时，可能存放的位置个数。
  直接映射关联度？关联度最低，为1
  全相联映射关联度？关联度最高，为Cache行数
  N-路组相联映射关联度？关联度居中，为N
  关联度和缺失率有什么关系？和命中时间的关系呢？
  缺失率：直接映射最高，全相联映射最低
  命中时间：直接映射最小，全相联映射最大
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/e630b2ef-c80b-48af-a7c7-183469f8af44)
  关联度与标记位大小有什么关系？
  关联度越高，总的标记位数越多，额外空间开销越大。
* 何时需要替换
  映射唯一，毫无选择，无需考虑替换策略
  每个主存数据有N个cache行可选择，需考虑替换
  每个主存数据可放到cache任意行中，需考虑替换
* 替换过程
  从主存取出一个新块
  选择一个有映射关系的空Cache行
  若对应行被占满时又需调入新主存块，则必须考虑从Cache行中替换出一个主存块。
* 常用的替换算法
  - 先进先出FIFO：总是把最先进入的那一块淘汰掉
  - 最近最少用LRU：总是把最近最少用的那一块淘汰掉，实际上并不移动主存块，而是通过计数值来确定cache行中主存块的使用情况。每行有一个计数器，每组4行时，每个计数器有2位。
  - 最不经常用LFU
  - 随机替换算法
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/81cd7709-17a2-4d48-9c92-59cb5b28a052)
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/cdabacc5-9bd7-46c4-9061-860876dd79d9)

## 8.Cache写策略和其他设计问题
为什么要保持在Cache和主存中数据的一致？
1.因为Cache中的内容是主存块副本，当对Cache中的内容进行更新时，就存在Cache和主存如何保持一致的问题。
2.当多个设备都运行访问主存时也会出现Cache一致性问题。当多个设备都允许访问主存时，例如I/O设备可直接读写内存时，如果Cache中的内容被修改，则I/O设备读出的对应主存单元的内容无效；若I/O设备修改了主存单元的内容，则Cache中对应的内容无效。
3.当多个CPU都带有各自的Cache而共享主存时，某个CPU修改了自身的Cache中的内容，则对应的主存单元和其他CPU中对应的内容都变为无效。
写操作有两种情况
1.写命中：要写的单元已经在Cache中
2.写不命中：要写的单元不在Cache中
* 对于写命中，有两种Cache的写策略
  - Write back
    只写cache不写主存，缺失时一次写回，每行有个修改位，大大降低主存带宽需求，控制可能很复杂。
  - Write through
    同时写Cache和主存单元
    每次写主存时间>100cycles，10%的存储指令使得CPI增加到1.0+100*10%=11
    使用写缓冲：在Cache和Memery之间加一个write buffer（CPU同时写数据到Cache和writer buffer,Memory controller将缓冲内容写主存）write buffer是一个FIFO队列一般有4项，在存数频率不高时效果好。当频繁写时，容易时缓存饱和，发生阻塞，如何解决写缓冲饱和？加一个二级Cache,使用write back方式得cache
处理Cache读比Cache写更容易，故指令Cache比数据Cache容易设计。
* 对于写不命中，有两种处理方式
  - Write Allocate（写分配）
    将主存块装入Cache，然后更新相应单元
    试图利用空间局部性，但每次都要从主存读一个块
  - Not Write Allocate(非写分配)
    直接写主存单元，不把主存块装入到cache
cache性能由缺失率确定，而缺失率与cache大小、block大小、Cache级数有关
Cache大小：Cache越大，Miss率越低，但成本越高
Block大小：Block大小与Cache大小有关，不能太大，也不能太小
* 系统中的Cache数目
  - 刚引入Cache时只有一个Cache。近年来多Cache系统成为主流
  - 多Cache系统中，需考虑两个方面：
    [1] 单级/多级？
    片内Cache:将Cache和CPU作在一个芯片上
    外部Cache：不做在CPU内而是独立设置一个Cache
    单级Cache:只用一个片内Cache
    多级Cache:同时使用L1 Cache和L2Cache，有些高端系统甚至有L3cache,L1Cache更靠近CPU，其速度比L2块，其容量比L2大
    [2]联合/分离？
    分离：指数据和指令分开存放在各自的数据和指令Cache中
    一般L1 Cache都是分离Cache，L1 Cache的命中时间比命中率更重要
    联合：指数据和指令都放在一个Cache中
    一般L2 Cache都是联合Cache,L2Cache的命中率比命中时间更重要
* 设计支持Cache的存储器系统
  指令执行若发生Cache缺失，必须到DRAM中取数据或指令
  在DRAM和Cache之间传输的单位是Block
  怎样的存储器组织使得Block传输最快（缺失损失最小）？
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/45694b5b-2186-4bd9-a07c-c6f2930c07a2)
可以有三种不同的组织形式。
假定一个Block有4个字，则缺失损失各为多少时钟？
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/32fe53d8-a227-4954-9fc5-e3a47a67a79a)
缺失损失为48个时钟周期，代价小，但速度慢。
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/d536a9db-1003-49ec-a331-f15286f1e529)
缺失损失各为24或12个时钟周期，速度快，但代价大。
- 交叉存取
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/207275d7-72fd-4ed7-a35b-2c5e29ad2a4e)
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/3b611065-6447-47a6-8293-ab008591b952)
* Cache友好程序
* 小结
![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/b7cef04f-769f-4a1e-b146-4982752125b0)
## 9.磁盘存储器
磁盘表面被分成许多同心圆，每个同心圆称为一个磁道。每个磁道都有一个编号，最外面的是0磁道。
每个磁道被划分为若干段（段又叫扇区），每个扇区的存储容量为512字节。每个扇区都有一个编号。
三十多年来，扇区大小一直是512字节。但近几年已迁移到更大、更高效的4096字节扇区，通常称为4K扇区。
磁盘格式化操作指在盘面上划分磁道和扇区，并在扇区中填写ID域信息的过程。
磁盘的操作流程如下：所有磁头同步寻道（由柱面号控制）->选择磁头（由磁头号控制）->被选中磁头等待扇区到达磁头下方（由扇区号控制）->读写该扇区中数据

- 磁盘信息以扇区为单位进行读写，平均存取时间为：
  T = 平均寻道时间 + 平均旋转等待时间 + 数据传输时间
  平均寻道时间--磁头寻找到指定磁道所需平均时间（约5ms）
  平均旋转等待时间--指定扇区旋转到磁头下方所需平均时间(约4~6ms)（转速：4200/5400/7200/10000rpm）
  数据传输时间--（大约0.01ms/扇区）
  磁盘响应时间=排队等待时间+磁盘控制器时间+寻道时间+旋转磁盘时间+数据传输时间
  磁盘转速非常重要。
  为什么实际的寻道时间可能只有1/3？访问局部性使得每次磁盘访问大多在局部几个磁道，实际寻道时间变少。
- 硬盘存储器的基本组成
  磁记录介质：用来保存信息
  磁盘驱动器：包括读写电路、读\写转换开关、磁头与磁头定位伺服系统
  磁盘控制器：包括控制逻辑、时序电路、并串转换和串并转换电路等。
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/34397a03-1c3f-4231-91b0-9cb2e1ab9304)

## 10.虚拟存储器的引入
* 存储管理技术的发展过程
  - 存储器资源的管理由操作系统来实现
      操作系统通过合理管理、调度计算机的硬件资源，使其高效被利用。存储器作为一种空间资源，由操作系统管理。CPU执行的程序总是在操作系统和用户程序之间切换。主存中同时存储操作系统和用户程序。磁盘中也存储操作系统和用户程序。CPU执行指令时，涉及到存储器操作，因此，CPU中专门有一个存储器管理部件MMU协助操作系统完成存储器访问。操作系统为进程分配存储器资源。
  操作系统在程序执行过程中的作用
      Shell进程生成子进程，子进程调用execve系统调用启动加载器，装入hello程序，初始化数据段和代码段等，最后跳转到第一条指令执行。在Hello程序执行过程中，hello程序本身没有直接访问键盘、显示器、磁盘和主存器这些硬件资源，而是依靠操作系统提供的服务来间接访问。操作系统是在应用程序和硬件之间插入的一个中间软件层。
  操作系统的两个主要的作用：
  - 硬件资源管理，以达到以下两个目的：统筹安排和调度硬件资源，以防止硬件资源被用户程序滥用。对于复杂低级设备，为用户程序提供一个简单一致的使用接口。
  - 为系统用户使用系统提供一个操作接口
- 存储器管理
  - 早期采用单道程序，系统的主存中包括
    - 操作系统（常驻监控程序）
    - 正在执行的一个用户程序
    所以无需进行存储管理，即使有也很简单
  - 现在都采用多道程序，系统的存储器中包含：
    - 操作系统
    - 若干个用户程序
      如果在存储器中进程数很少，则由于进程花费很多时间来等待I/O,常使处理机处于空闲状态。因此，存储器需要进行合理分配，尽可能让更多进程进入存储器。
  - 在多道程序系统中，存储器的用户部分须进一步划分以适应多个进程。划分的任务由OS动态执行，这些称为存储管理。
- 使系统中尽量多地存储用户程序地解决办法有：
  （1）扩大主存（程序越来越长、主存贵，不是根本办法）
  （2）采用交换方式和覆盖技术，程序员把程序分成许多片段，每个片段都能装入内存。程序运行时，一个片段在内存运行结束时，它读入下一个片段执行，以此类推，直到程序完成。
  缺点：程序员需进行片段划分、安排每个片段在辅存地存放位置，并读入和保存片段；空间利用率差。
  （3）虚拟存储器，采用分页方式，按需调页，在外存和主存间以固定页面进行调度。虚拟存储器方式下，引入了虚拟地址空间的概念。
- 早期分页方式的概念
  1961年，英国曼切斯特研究人员提出一种自动执行overlay的方式。
  动机：把程序员大量繁琐的存储管理工作中解放出来，使得程序员编程时不用管主存容量的大小。
  基本思想：把地址空间和主存容量的概念区分开来。程序员在地址空间里编写程序，而程序则在真正的内存中运行。由一个专门的机制实现地址空间和实际主存之间的映射。
  程序员编写程序的空间比执行程序的空间大的多，怎么自动执行程序？
  将地址空间划分为4K大小的区间，装入内存的总是其中的一个区间,执行到某个区间时，把该区间的地址 ** 自动 **映射到0~4095之间,程序员在0~65535范围内写程序，完全不用管在多大的主存空间上执行，所以这种方式对程序员来说，是透明的。可寻址的地址空间是一种虚拟内存。
  ![image](https://github.com/kyre0e/kyre0e.github.io/assets/169347540/8ff81234-e54a-4c83-bc3f-9d468ad39558)
后来把区间称为页，主存中存放页的区域称为页框，早期主存只有一个页框。
* 分页
  基本思想：内存被分成固定长且比较小的存储块（页框、实页、物理页），每个进程也被划分成固定长的程序块（页、虚页、逻辑页），程序可装到存储器中可用的存储块中，无需用连续页框来存放一个进程，操作系统为每个进程生成一个页表，通过页表实现逻辑地址向物理地址转换
  逻辑地址：程序中指令所用的地址（进程所在地址空间），也称为虚拟地址。
  物理地址：存放指令或数据的实际内存地址，也称为实地址、主存地址。
  虚拟存储管理的概念：采用按需调页方式分配主存。
* 虚拟存储系统的基本概念
  虚拟存储技术的引入用来解决一对矛盾：一方面，由于技术和成本等原因，主存容量受到限制。另一方面，系统程序和应用程序要求主存容量越来越大。
  虚拟存储技术的实质：程序员在比实际主存空间大得多的逻辑地址空间中编写程序，程序执行时，把当前需要的程序段和相应的数据块调入主存，其他暂不用的部分放在磁盘上。指令执行时，通过硬件将逻辑地址也称虚拟地址或虚地址转化为物理地址也称主存地址或实地址。在发生程序或数据访问失效时，由操作系统进行主存和磁盘之间的信息交换。
  虚拟存储器机制由硬件与操作系统共同协作实现，涉及到操作系统中的许多概念，如进程、进程的上下文切换、存储器分配、虚拟地址空间、缺页处理等。
* 虚拟存储器的基本概念
  - 按需调页
  - 虚拟地址空间
* 虚拟存储器方式
  - 三种方式：页式、段式、段页式
  - 逻辑地址--物理地址的转换
  - 页表、缺页处理
* 替换策略
* 快表
* 存储保护
  - 地址越界检查
  - 存取权限检查
## 11.虚拟存储器的实现
# 第四章总结
***
